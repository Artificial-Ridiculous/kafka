[2019-06-05 19:09:30,303] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:19:30,303] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:29:30,303] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:39:30,303] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:49:30,303] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:52:05,981] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1507349088, epoch=7472) to node 1: java.io.IOException: Connection to 1 was disconnected before the response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-06-05 19:52:05,983] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1507349088, epoch=7472)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to 1 was disconnected before the response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:100)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:99)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-06-05 19:52:07,990] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (ubuntu/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-06-05 19:52:07,990] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1507349088, epoch=INITIAL) to node 1: java.io.IOException: Connection to ubuntu:9093 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-06-05 19:52:07,990] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={my-replicated-topic-0=(fetchOffset=2, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1507349088, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to ubuntu:9093 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:71)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:94)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-06-05 19:52:09,992] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (ubuntu/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-06-05 19:52:09,992] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1507349088, epoch=INITIAL) to node 1: java.io.IOException: Connection to ubuntu:9093 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-06-05 19:52:09,992] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={my-replicated-topic-0=(fetchOffset=2, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1507349088, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to ubuntu:9093 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:71)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:94)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-06-05 19:52:11,994] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Connection to node 1 (ubuntu/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2019-06-05 19:52:11,995] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1507349088, epoch=INITIAL) to node 1: java.io.IOException: Connection to ubuntu:9093 (id: 1 rack: null) failed.. (org.apache.kafka.clients.FetchSessionHandler)
[2019-06-05 19:52:11,995] WARN [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error in response for fetch request (type=FetchRequest, replicaId=2, maxWait=500, minBytes=1, maxBytes=10485760, fetchData={my-replicated-topic-0=(fetchOffset=2, logStartOffset=0, maxBytes=1048576, currentLeaderEpoch=Optional[0])}, isolationLevel=READ_UNCOMMITTED, toForget=, metadata=(sessionId=1507349088, epoch=INITIAL)) (kafka.server.ReplicaFetcherThread)
java.io.IOException: Connection to ubuntu:9093 (id: 1 rack: null) failed.
	at org.apache.kafka.clients.NetworkClientUtils.awaitReady(NetworkClientUtils.java:71)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:94)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:192)
	at kafka.server.AbstractFetcherThread.kafka$server$AbstractFetcherThread$$processFetchRequest(AbstractFetcherThread.scala:274)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:132)
	at kafka.server.AbstractFetcherThread$$anonfun$maybeFetch$1.apply(AbstractFetcherThread.scala:131)
	at scala.Option.foreach(Option.scala:257)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:131)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:113)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:82)
[2019-06-05 19:52:13,729] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my-replicated-topic-0) (kafka.server.ReplicaFetcherManager)
[2019-06-05 19:52:13,735] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=0, host=ubuntu:9092) for partitions Map(my-replicated-topic-0 -> (offset=2, leaderEpoch=1)) (kafka.server.ReplicaFetcherManager)
[2019-06-05 19:52:13,736] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-06-05 19:52:13,738] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-06-05 19:52:13,741] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-06-05 19:52:13,741] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-06-05 19:52:13,777] INFO [Log partition=my-replicated-topic-0, dir=/tmp/kafka-logs-2] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-06-05 19:53:38,159] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-18, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-48, __consumer_offsets-2, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-12, __consumer_offsets-26, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-06-05 19:53:38,175] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,177] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-06-05 19:53:38,179] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,180] INFO [Partition __consumer_offsets-0 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2019-06-05 19:53:38,181] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,185] INFO [Partition __consumer_offsets-0 broker=2] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,198] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,199] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-06-05 19:53:38,202] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,203] INFO [Partition __consumer_offsets-48 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2019-06-05 19:53:38,204] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,204] INFO [Partition __consumer_offsets-48 broker=2] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,213] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,222] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-06-05 19:53:38,223] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,224] INFO [Partition __consumer_offsets-10 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2019-06-05 19:53:38,224] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,225] INFO [Partition __consumer_offsets-10 broker=2] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,243] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,244] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-06-05 19:53:38,248] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,248] INFO [Partition __consumer_offsets-26 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2019-06-05 19:53:38,249] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,249] INFO [Partition __consumer_offsets-26 broker=2] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,258] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,258] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-06-05 19:53:38,260] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,260] INFO [Partition __consumer_offsets-42 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2019-06-05 19:53:38,260] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,261] INFO [Partition __consumer_offsets-42 broker=2] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,269] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,270] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-06-05 19:53:38,272] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,273] INFO [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2019-06-05 19:53:38,273] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,273] INFO [Partition __consumer_offsets-4 broker=2] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,288] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,289] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-06-05 19:53:38,290] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,290] INFO [Partition __consumer_offsets-20 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2019-06-05 19:53:38,290] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,291] INFO [Partition __consumer_offsets-20 broker=2] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,297] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,297] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-06-05 19:53:38,301] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,302] INFO [Partition __consumer_offsets-36 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2019-06-05 19:53:38,302] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,302] INFO [Partition __consumer_offsets-36 broker=2] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,307] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,309] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-06-05 19:53:38,309] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,310] INFO [Partition __consumer_offsets-14 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2019-06-05 19:53:38,310] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,310] INFO [Partition __consumer_offsets-14 broker=2] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,319] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,320] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-06-05 19:53:38,321] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,321] INFO [Partition __consumer_offsets-30 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2019-06-05 19:53:38,321] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,322] INFO [Partition __consumer_offsets-30 broker=2] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,331] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,333] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-06-05 19:53:38,334] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,339] INFO [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2019-06-05 19:53:38,339] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,339] INFO [Partition __consumer_offsets-46 broker=2] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,347] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,350] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-06-05 19:53:38,351] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,352] INFO [Partition __consumer_offsets-8 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2019-06-05 19:53:38,352] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,352] INFO [Partition __consumer_offsets-8 broker=2] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,359] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,359] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-06-05 19:53:38,360] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,360] INFO [Partition __consumer_offsets-24 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2019-06-05 19:53:38,360] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,360] INFO [Partition __consumer_offsets-24 broker=2] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,369] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,369] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-06-05 19:53:38,371] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,371] INFO [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2019-06-05 19:53:38,371] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,371] INFO [Partition __consumer_offsets-40 broker=2] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,385] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,385] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-06-05 19:53:38,386] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,387] INFO [Partition __consumer_offsets-2 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2019-06-05 19:53:38,387] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,388] INFO [Partition __consumer_offsets-2 broker=2] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,394] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,394] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2019-06-05 19:53:38,395] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,396] INFO [Partition __consumer_offsets-18 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2019-06-05 19:53:38,396] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,396] INFO [Partition __consumer_offsets-18 broker=2] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,410] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,410] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-06-05 19:53:38,411] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,411] INFO [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2019-06-05 19:53:38,412] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,412] INFO [Partition __consumer_offsets-34 broker=2] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,421] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,421] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-06-05 19:53:38,422] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,422] INFO [Partition __consumer_offsets-12 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2019-06-05 19:53:38,422] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,422] INFO [Partition __consumer_offsets-12 broker=2] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,430] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,430] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-06-05 19:53:38,432] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,432] INFO [Partition __consumer_offsets-28 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2019-06-05 19:53:38,432] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,433] INFO [Partition __consumer_offsets-28 broker=2] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,444] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,445] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-06-05 19:53:38,446] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,447] INFO [Partition __consumer_offsets-38 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2019-06-05 19:53:38,447] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,448] INFO [Partition __consumer_offsets-38 broker=2] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,455] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,456] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-06-05 19:53:38,456] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,457] INFO [Partition __consumer_offsets-44 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2019-06-05 19:53:38,457] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,457] INFO [Partition __consumer_offsets-44 broker=2] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,461] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,462] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-06-05 19:53:38,462] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,463] INFO [Partition __consumer_offsets-6 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2019-06-05 19:53:38,463] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,463] INFO [Partition __consumer_offsets-6 broker=2] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,474] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,479] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-06-05 19:53:38,481] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,482] INFO [Partition __consumer_offsets-16 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2019-06-05 19:53:38,482] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,482] INFO [Partition __consumer_offsets-16 broker=2] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,490] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,491] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-06-05 19:53:38,491] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,492] INFO [Partition __consumer_offsets-22 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2019-06-05 19:53:38,492] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,493] INFO [Partition __consumer_offsets-22 broker=2] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,503] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-06-05 19:53:38,504] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs-2] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-06-05 19:53:38,505] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-2 with properties {compression.type -> producer, message.format.version -> 2.1-IV2, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}. (kafka.log.LogManager)
[2019-06-05 19:53:38,506] INFO [Partition __consumer_offsets-32 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2019-06-05 19:53:38,506] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-06-05 19:53:38,506] INFO [Partition __consumer_offsets-32 broker=2] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-06-05 19:53:38,512] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,518] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,518] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,526] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,527] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,527] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,528] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,528] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,528] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,529] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,529] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,529] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,529] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,529] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,529] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,530] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,530] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,530] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,530] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,530] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,531] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,531] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,531] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,531] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,531] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,531] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,531] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,535] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,536] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,536] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,538] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,538] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,538] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,539] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,539] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,546] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,546] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,546] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,546] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,547] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,547] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,548] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,548] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,548] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,549] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,550] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,561] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,565] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-48 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,566] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,566] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:53:38,587] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-15623 in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member consumer-1-3e0f89db-8b00-4d69-aa17-c6337ac24128) (kafka.coordinator.group.GroupCoordinator)
[2019-06-05 19:53:38,596] INFO [GroupCoordinator 2]: Stabilized group console-consumer-15623 generation 1 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2019-06-05 19:53:38,608] INFO [GroupCoordinator 2]: Assignment received from leader for group console-consumer-15623 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-06-05 19:54:18,050] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-15623 in state PreparingRebalance with old generation 1 (__consumer_offsets-48) (reason: removing member consumer-1-3e0f89db-8b00-4d69-aa17-c6337ac24128 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-06-05 19:54:18,059] INFO [GroupCoordinator 2]: Group console-consumer-15623 with generation 2 is now empty (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2019-06-05 19:57:28,770] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(my-replicated-topic-0) (kafka.server.ReplicaFetcherManager)
[2019-06-05 19:57:28,779] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker BrokerEndPoint(id=1, host=ubuntu:9093) for partitions Map(my-replicated-topic-0 -> (offset=2, leaderEpoch=2)) (kafka.server.ReplicaFetcherManager)
[2019-06-05 19:57:28,780] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2019-06-05 19:57:28,781] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2019-06-05 19:57:28,786] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=250572222, epoch=628) to node 0: java.io.IOException: Client was shutdown before response was read. (org.apache.kafka.clients.FetchSessionHandler)
[2019-06-05 19:57:28,787] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2019-06-05 19:57:28,789] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2019-06-05 19:57:28,807] INFO [Log partition=my-replicated-topic-0, dir=/tmp/kafka-logs-2] Truncating to 2 has no effect as the largest offset in the log is 1 (kafka.log.Log)
[2019-06-05 19:59:30,305] INFO [GroupMetadataManager brokerId=2] Group console-consumer-15623 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-06-05 19:59:30,308] INFO [GroupMetadataManager brokerId=2] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
